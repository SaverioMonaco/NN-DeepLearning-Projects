{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd581c9-b9e4-4cb0-bd4d-dcc781d5d906",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# NEURAL NETWORKS AND DEEP LEARNING\n",
    "\n",
    "### A.A. 2021/22 (6 CFU) - Dr. Alberto Testolin, Dr. Umberto Michieli\n",
    "\n",
    "# Homework 1 - Supervised Deep Learning\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128af43b-542f-4124-9700-72be4837691b",
   "metadata": {},
   "source": [
    "## Classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a89872-5c7f-40dc-ad13-e60c12007037",
   "metadata": {},
   "source": [
    "* The goal is to train a neural network that maps an input image (from fashionMNIST) to one of ten classes (multi-class classification problem with mutually exclusive classes).\n",
    "* Define a proper loss (e.g. [torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss))\n",
    "* Also here, consider to create a validation set from you training data, or use a k-fold cross-validation strategy.\n",
    "* Pay attention to the shape, data type and output values range. If needed, modify them accordingly to your implementation (read carefully the documentation of the layers that you use, e.g. [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)).\n",
    "* Explore different optimizers, acivation functions, network architectures. Analyze the effect of different regularization methods, such as dropout layers, random transformations (image rotation, scaling, add noise...) or L2 regularization (weight decay)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e6a947-2dba-4e28-a68c-dfd659178e7d",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f62da4-da28-4df5-b206-b9db92521a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "#### IMPORTS ####\n",
    "#################\n",
    "\n",
    "# Arrays\n",
    "import numpy as np\n",
    "\n",
    "# Deep Learning stuff\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Images display and plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90407dd9-ed20-4182-b959-442112bbf17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the values of the seeds for reproducibility\n",
    "torch.manual_seed(2012264)    \n",
    "np.random.seed(2012264)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "267abf10-fb9a-49d4-8611-eff0cfcce644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have already the datafolder, do not download.\n",
    "if(os.path.isdir('./classifier_data/FashionMNIST')):\n",
    "    train_dataset = torchvision.datasets.FashionMNIST('classifier_data', train=True, download=False)\n",
    "    test_dataset  = torchvision.datasets.FashionMNIST('classifier_data', train=False, download=False)\n",
    "else:\n",
    "    train_dataset = torchvision.datasets.FashionMNIST('classifier_data', train=True, download=True)\n",
    "    test_dataset  = torchvision.datasets.FashionMNIST('classifier_data', train=False, download=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "236e0588-25e4-4698-a254-bcd8193eab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9dfa00e-ec96-4212-8305-a7ff085d79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnistimg(dataset, sample, output = False, size = 3):\n",
    "    '''\n",
    "    Display the sample-th image from dataset (can be trainingset or testset) and its true\n",
    "    label.\n",
    "    Eventually display the predicted label in output.\n",
    "    Size of the image can be changed changing size input parameter\n",
    "    '''\n",
    "    \n",
    "    description = ['T-shirt/top','Trouser','Pullover',\n",
    "                   'Dress','Coat','Sandal','Shirt',\n",
    "                   'Sneaker','Bag','Ankle boot']\n",
    "    \n",
    "    image = dataset[sample][0]\n",
    "    label = dataset[sample][1]\n",
    "\n",
    "    fig = plt.figure(figsize=(size,size))\n",
    "    plt.imshow(image, cmap='Greys')\n",
    "    \n",
    "    print(f\"Sample: {sample_index}\")\n",
    "    print(f\"True Label: {description[label]}\")\n",
    "    \n",
    "    if output:\n",
    "        print(f\"Prediction: {description[output]}\")\n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8127ade2-dad3-4e6c-8739-5659e0c7d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0\n",
      "True Label: T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnistimg(train_dataset, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
