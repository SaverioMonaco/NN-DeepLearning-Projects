{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd581c9-b9e4-4cb0-bd4d-dcc781d5d906",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# NEURAL NETWORKS AND DEEP LEARNING\n",
    "\n",
    "### A.A. 2021/22 (6 CFU) - Dr. Alberto Testolin, Dr. Umberto Michieli\n",
    "\n",
    "### Saverio Monaco\n",
    "##### MAT: 2012264\n",
    "\n",
    "# Homework 3 - Deep Reinforcement Learning\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c01cf3-ee6a-4aa3-a1f9-5d22c6918a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from collections import deque # fixed size FIFO list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc28e950-55fc-45f1-95f3-da78be229d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from gym.wrappers import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff56bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742bba9d-45b6-4857-b692-3dc61d18fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3566329-7bb9-46bd-8735-e9b1fadf9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "\n",
    "def show_videos():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    mp4list.sort()\n",
    "    for mp4 in mp4list:\n",
    "        print(f\"\\nSHOWING VIDEO {mp4}\")\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                    </video>'''.format(encoded.decode('ascii'))))\n",
    "    \n",
    "def wrap_env(env, video_callable=None):\n",
    "    env = Monitor(env, './video', force=True, video_callable=video_callable)\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799b88eb-ed7b-4ba6-8010-744e936f20ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity) # Define a queue with maxlen \"capacity\"\n",
    "\n",
    "    def push(self, state, action, next_state, reward):\n",
    "        # TODO: Add the tuple (state, action, next_state, reward) to the queue\n",
    "        self.memory.append( (state, action, next_state, reward) )\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        batch_size = min(batch_size, len(self)) # Get all the samples if the requested batch_size is higher than the number of sample currently in the memory\n",
    "        return random.sample(self.memory, batch_size) # Randomly select \"batch_size\" samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory) # Return the number of samples currently stored in the memory\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5edc57bb-d7e3-445a-a6b6-9109c90164ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT MEMORY SIZE: 0\n",
      "CURRENT MEMORY SIZE: 1\n",
      "CURRENT MEMORY SIZE: 2\n",
      "CURRENT MEMORY SIZE: 3\n",
      "CURRENT MEMORY SIZE: 3\n",
      "CURRENT MEMORY SIZE: 3\n",
      "\n",
      "CONTENT OF THE MEMORY\n",
      "deque([(3, 3, 3, 3), (4, 4, 4, 4), (5, 5, 5, 5)], maxlen=3)\n",
      "\n",
      "RANDOM SAMPLING\n",
      "[(4, 4, 4, 4), (5, 5, 5, 5)]\n",
      "[(3, 3, 3, 3), (4, 4, 4, 4)]\n",
      "[(5, 5, 5, 5), (4, 4, 4, 4)]\n",
      "[(4, 4, 4, 4), (5, 5, 5, 5)]\n",
      "[(4, 4, 4, 4), (5, 5, 5, 5)]\n"
     ]
    }
   ],
   "source": [
    "# Define the replay memory\n",
    "replay_mem = ReplayMemory(capacity=3)\n",
    "\n",
    "# Push some samples\n",
    "print(f\"CURRENT MEMORY SIZE: {len(replay_mem)}\")\n",
    "replay_mem.push(1,1,1,1)\n",
    "print(f\"CURRENT MEMORY SIZE: {len(replay_mem)}\")\n",
    "replay_mem.push(2,2,2,2)\n",
    "print(f\"CURRENT MEMORY SIZE: {len(replay_mem)}\")\n",
    "replay_mem.push(3,3,3,3)\n",
    "print(f\"CURRENT MEMORY SIZE: {len(replay_mem)}\")\n",
    "replay_mem.push(4,4,4,4)\n",
    "print(f\"CURRENT MEMORY SIZE: {len(replay_mem)}\")\n",
    "replay_mem.push(5,5,5,5)\n",
    "print(f\"CURRENT MEMORY SIZE: {len(replay_mem)}\")\n",
    "\n",
    "# Check the content of the memory\n",
    "print('\\nCONTENT OF THE MEMORY')\n",
    "print(replay_mem.memory)\n",
    "\n",
    "# Random sample\n",
    "print('\\nRANDOM SAMPLING')\n",
    "for i in range(5):\n",
    "    print(replay_mem.sample(2)) # Select 2 samples randomly from the memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356a14e9-9520-40d0-b64e-47812944f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_space_dim, action_space_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(state_space_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,action_space_dim)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a02d52-c409-4b59-8108-356dbfdddb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an example network\n",
    "net = DQN(state_space_dim=4, action_space_dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d014827d-0573-4e79-9524-0cda30d30d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_epsilon_greedy(net, state, epsilon):\n",
    "    \n",
    "    if epsilon > 1 or epsilon < 0:\n",
    "        raise Exception('The epsilon value must be between 0 and 1')\n",
    "                \n",
    "    # Evaluate the network output from the current state\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float32) # Convert the state to tensor\n",
    "        net_out = net(state)\n",
    "\n",
    "    # Get the best action (argmax of the network output)\n",
    "    best_action = int(net_out.argmax())\n",
    "    # Get the number of possible actions\n",
    "    action_space_dim = net_out.shape[-1]\n",
    "\n",
    "    # Select a non optimal action with probability epsilon, otherwise choose the best action\n",
    "    if random.random() < epsilon:\n",
    "        # List of non-optimal actions\n",
    "        non_optimal_actions = [a for a in range(action_space_dim) if a != best_action]\n",
    "        # Select randomly\n",
    "        action = random.choice(non_optimal_actions)\n",
    "    else:\n",
    "        # Select best action\n",
    "        action = best_action\n",
    "        \n",
    "    return action, net_out.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "363e4016-28ac-4cc5-8ead-bb67a7ab51ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION: 0\n",
      "Q-VALUES: [ 0.0044669  -0.00997966]\n"
     ]
    }
   ],
   "source": [
    "# Test if it works as expected\n",
    "state = (0, 0, 0, 0)\n",
    "epsilon = 0.5\n",
    "chosen_action, q_values = choose_action_epsilon_greedy(net, state, epsilon)\n",
    "\n",
    "print(f\"ACTION: {chosen_action}\")\n",
    "print(f\"Q-VALUES: {q_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414a9d2b-7db1-4d9b-bd2d-063ebc286195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action_softmax(net, state, temperature):\n",
    "    net.to(device)\n",
    "    if temperature < 0:\n",
    "        raise Exception('The temperature value must be greater than or equal to 0 ')\n",
    "        \n",
    "    # If the temperature is 0, just select the best action using the eps-greedy policy with epsilon = 0\n",
    "    if temperature == 0:\n",
    "        return choose_action_epsilon_greedy(net.to(device), state, 0)\n",
    "    \n",
    "    # Evaluate the network output from the current state\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "        net_out = net(state.to(device))\n",
    "\n",
    "    # Apply softmax with temp\n",
    "    temperature = max(temperature, 1e-8) # set a minimum to the temperature for numerical stability\n",
    "    softmax_out = nn.functional.softmax(net_out / temperature, dim=0).cpu().numpy()\n",
    "                \n",
    "    # Sample the action using softmax output as mass pdf\n",
    "    all_possible_actions = np.arange(0, softmax_out.shape[-1])\n",
    "    action = np.random.choice(all_possible_actions, p=softmax_out) # this samples a random element from \"all_possible_actions\" with the probability distribution p (softmax_out in this case)\n",
    "    \n",
    "    return action, net_out.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b373b2a5-c166-4f9b-8115-284eba1a0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION: 1\n",
      "Q-VALUES: [ 0.0044669  -0.00997966]\n"
     ]
    }
   ],
   "source": [
    "state = (0, 0, 0, 0)\n",
    "temperature = 1\n",
    "chosen_action, q_values = choose_action_softmax(net, state, temperature)\n",
    "\n",
    "print(f\"ACTION: {chosen_action}\")\n",
    "print(f\"Q-VALUES: {q_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f79036f-016f-4d77-aa38-758a9f919d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Exploration profile (Softmax temperature)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Define exploration profile\n",
    "initial_value = 5\n",
    "num_iterations = 650\n",
    "exp_decay = np.exp(-np.log(initial_value) / num_iterations * 6) # We compute the exponential decay in such a way the shape of the exploration profile does not depend on the number of iterations\n",
    "exploration_profile = [initial_value * (exp_decay ** i) for i in range(num_iterations)]\n",
    "\n",
    "### Plot exploration profile\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(exploration_profile)\n",
    "plt.grid()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Exploration profile (Softmax temperature)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93f183e-1fdf-485d-b97c-f7e6cba215a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE SPACE SIZE: 4\n",
      "ACTION SPACE SIZE: 2\n"
     ]
    }
   ],
   "source": [
    "### Create environment\n",
    "env = gym.make('CartPole-v1') # Initialize the Gym environment\n",
    "env.seed(0) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "# Get the shapes of the state space (observation_space) and action space (action_space)\n",
    "state_space_dim = env.observation_space.shape[0]\n",
    "action_space_dim = env.action_space.n\n",
    "\n",
    "print(f\"STATE SPACE SIZE: {state_space_dim}\")\n",
    "print(f\"ACTION SPACE SIZE: {action_space_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0515fef-d748-452e-b4a0-e58a5f155f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE 1 - FINAL SCORE: 14.0\n",
      "EPISODE 2 - FINAL SCORE: 16.0\n",
      "EPISODE 3 - FINAL SCORE: 14.0\n",
      "EPISODE 4 - FINAL SCORE: 21.0\n",
      "EPISODE 5 - FINAL SCORE: 14.0\n",
      "EPISODE 6 - FINAL SCORE: 15.0\n",
      "EPISODE 7 - FINAL SCORE: 11.0\n",
      "EPISODE 8 - FINAL SCORE: 14.0\n",
      "EPISODE 9 - FINAL SCORE: 24.0\n",
      "EPISODE 10 - FINAL SCORE: 14.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Gym environment\n",
    "env = gym.make('CartPole-v1') \n",
    "env.seed(0) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "# Let's try for a total of 10 episodes\n",
    "for num_episode in range(10): \n",
    "    # Reset the environment and get the initial state\n",
    "    state = env.reset()\n",
    "    # Reset the score. The final score will be the total amount of steps before the pole falls\n",
    "    score = 0\n",
    "    done = False\n",
    "    # Go on until the pole falls off or the score reach 490\n",
    "    while not done and score < 490:\n",
    "      # Choose a random action\n",
    "      action = random.choice([0, 1])\n",
    "      # Apply the action and get the next state, the reward and a flag \"done\" that is True if the game is ended\n",
    "      next_state, reward, done, info = env.step(action)\n",
    "      # Visually render the environment (optional, comment this line to speed up the simulation)\n",
    "      env.render()\n",
    "      # Update the final score (+1 for each step)\n",
    "      score += reward \n",
    "      # Set the current state for the next iteration\n",
    "      state = next_state\n",
    "      # Check if the episode ended (the pole fell down)\n",
    "    # Print the final score\n",
    "    print(f\"EPISODE {num_episode + 1} - FINAL SCORE: {score}\") \n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1097d711-f731-44af-9a66-d2db3c9c3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "gamma = 0.97   # gamma parameter for the long term reward\n",
    "replay_memory_capacity = 100   # Replay memory capacity\n",
    "lr = 1e-2   # Optimizer learning rate\n",
    "target_net_update_steps = 10   # Number of episodes to wait before updating the target network\n",
    "batch_size = 128   # Number of samples to take from the replay memory for each update\n",
    "bad_state_penalty = 0   # Penalty to the reward when we are in a bad state (in this case when the pole falls down) \n",
    "min_samples_for_training = 1000   # Minimum samples in the replay memory to enable the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19ef5299-d5ad-449e-9c2a-35e25f32a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the replay memory\n",
    "replay_mem = ReplayMemory(replay_memory_capacity)    \n",
    "\n",
    "### Initialize the policy network\n",
    "policy_net = DQN(state_space_dim, action_space_dim)\n",
    "\n",
    "### Initialize the target network with the same weights of the policy network\n",
    "target_net = DQN(state_space_dim, action_space_dim)\n",
    "target_net.load_state_dict(policy_net.state_dict()) # This will copy the weights of the policy network to the target network\n",
    "\n",
    "### Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(policy_net.parameters(), lr=lr) # The optimizer will update ONLY the parameters of the policy network\n",
    "\n",
    "### Initialize the loss function (Huber loss)\n",
    "loss_fn = nn.SmoothL1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9625c582-0b92-4c38-a871-54b58392b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_step(policy_net, target_net, replay_mem, gamma, optimizer, loss_fn, batch_size):\n",
    "    policy_net.to(device)\n",
    "    target_net.to(device)\n",
    "    # Sample the data from the replay memory\n",
    "    batch = replay_mem.sample(batch_size)\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    # Create tensors for each element of the batch\n",
    "    states      = torch.tensor([s[0] for s in batch], dtype=torch.float32, device=device)\n",
    "    actions     = torch.tensor([s[1] for s in batch], dtype=torch.int64, device=device)\n",
    "    rewards     = torch.tensor([s[3] for s in batch], dtype=torch.float32, device=device)\n",
    "\n",
    "    # Compute a mask of non-final states (all the elements where the next state is not None)\n",
    "    non_final_next_states = torch.tensor([s[2] for s in batch if s[2] is not None], dtype=torch.float32, device=device) # the next state can be None if the game has ended\n",
    "    non_final_mask = torch.tensor([s[2] is not None for s in batch], dtype=torch.bool, device=device)\n",
    "\n",
    "    # Compute all the Q values (forward pass)\n",
    "    policy_net.train()\n",
    "    q_values = policy_net(states)\n",
    "    # Select the proper Q value for the corresponding action taken Q(s_t, a)\n",
    "    state_action_values = q_values.gather(1, actions.unsqueeze(1))\n",
    "\n",
    "    # Compute the value function of the next states using the target network V(s_{t+1}) = max_a( Q_target(s_{t+1}, a)) )\n",
    "    with torch.no_grad():\n",
    "        target_net.eval()\n",
    "        q_values_target = target_net(non_final_next_states)\n",
    "    next_state_max_q_values = torch.zeros(batch_size, device=device)\n",
    "    next_state_max_q_values[non_final_mask] = q_values_target.max(dim=1)[0]\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = rewards + (next_state_max_q_values * gamma)\n",
    "    expected_state_action_values = expected_state_action_values.unsqueeze(1) # Set the required tensor shape\n",
    "\n",
    "    # Compute the Huber loss\n",
    "    loss = loss_fn(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Apply gradient clipping (clip all the gradients greater than 2 for training stability)\n",
    "    nn.utils.clip_grad_norm_(policy_net.parameters(), 2)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d67502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0,\n",
       " 4.926267305681092,\n",
       " 4.8536219134044885,\n",
       " 4.7820477892283675,\n",
       " 4.7115291356560505,\n",
       " 4.642050388149259,\n",
       " 4.573596211692783,\n",
       " 4.506151497409811,\n",
       " 4.439701359227169,\n",
       " 4.374231130589742,\n",
       " 4.309726361223337,\n",
       " 4.246172813945293,\n",
       " 4.183556461522116,\n",
       " 4.1218634835734544,\n",
       " 4.0610802635217365,\n",
       " 4.0011933855867765,\n",
       " 3.942189631824715,\n",
       " 3.884055979210615,\n",
       " 3.8267795967640823,\n",
       " 3.7703478427172743,\n",
       " 3.7147482617246688,\n",
       " 3.6599685821139802,\n",
       " 3.6059967131776167,\n",
       " 3.5528207425040743,\n",
       " 3.5004289333486884,\n",
       " 3.448809722043156,\n",
       " 3.3979517154432592,\n",
       " 3.3478436884142218,\n",
       " 3.298474581353155,\n",
       " 3.2498334977480345,\n",
       " 3.2019097017726743,\n",
       " 3.154692615917164,\n",
       " 3.1081718186532563,\n",
       " 3.0623370421341756,\n",
       " 3.0171781699283455,\n",
       " 2.9726852347865442,\n",
       " 2.928848416441974,\n",
       " 2.885658039442787,\n",
       " 2.8431045710165606,\n",
       " 2.8011786189662695,\n",
       " 2.7598709295972896,\n",
       " 2.7191723856749617,\n",
       " 2.679074004412284,\n",
       " 2.6395669354872715,\n",
       " 2.600642459089555,\n",
       " 2.5622919839957903,\n",
       " 2.5245070456734404,\n",
       " 2.4872793044125263,\n",
       " 2.4506005434849274,\n",
       " 2.4144626673308225,\n",
       " 2.3788576997718787,\n",
       " 2.3437777822507866,\n",
       " 2.3092151720967573,\n",
       " 2.2751622408165986,\n",
       " 2.241611472410988,\n",
       " 2.2085554617155805,\n",
       " 2.1759869127665743,\n",
       " 2.143898637190382,\n",
       " 2.1122835526170456,\n",
       " 2.0811346811170512,\n",
       " 2.050445147661195,\n",
       " 2.0202081786031565,\n",
       " 1.990417100184456,\n",
       " 1.9610653370614504,\n",
       " 1.9321464108540585,\n",
       " 1.903653938715883,\n",
       " 1.8755816319254182,\n",
       " 1.847923294498035,\n",
       " 1.8206728218184323,\n",
       " 1.7938241992932558,\n",
       " 1.767371501023586,\n",
       " 1.7413088884970016,\n",
       " 1.7156306092989322,\n",
       " 1.6903309958430122,\n",
       " 1.6654044641201584,\n",
       " 1.640845512466095,\n",
       " 1.6166487203470519,\n",
       " 1.5928087471633714,\n",
       " 1.5693203310707555,\n",
       " 1.5461782878188979,\n",
       " 1.523377509607241,\n",
       " 1.500912963957607,\n",
       " 1.4787796926034524,\n",
       " 1.4569728103955046,\n",
       " 1.4354875042235342,\n",
       " 1.4143190319540289,\n",
       " 1.3934627213835329,\n",
       " 1.3729139692074197,\n",
       " 1.3526682400038736,\n",
       " 1.3327210652328536,\n",
       " 1.3130680422498167,\n",
       " 1.2937048333339902,\n",
       " 1.2746271647309684,\n",
       " 1.2558308257094315,\n",
       " 1.2373116676317724,\n",
       " 1.21906560303843,\n",
       " 1.201088604745724,\n",
       " 1.1833767049569963,\n",
       " 1.165925994386854,\n",
       " 1.1487326213983349,\n",
       " 1.1317927911527907,\n",
       " 1.1151027647723082,\n",
       " 1.098658858514483,\n",
       " 1.0824574429593612,\n",
       " 1.0664949422083712,\n",
       " 1.050767833095069,\n",
       " 1.0352726444075209,\n",
       " 1.0200059561221555,\n",
       " 1.0049643986489114,\n",
       " 0.9901446520875183,\n",
       " 0.9755434454947441,\n",
       " 0.9611575561624485,\n",
       " 0.9469838089062815,\n",
       " 0.933019075364873,\n",
       " 0.9192602733093553,\n",
       " 0.9057043659630684,\n",
       " 0.8923483613312972,\n",
       " 0.8791893115408934,\n",
       " 0.8662243121896342,\n",
       " 0.8534505017051773,\n",
       " 0.8408650607134681,\n",
       " 0.8284652114164608,\n",
       " 0.8162482169790168,\n",
       " 0.8042113809248432,\n",
       " 0.7923520465413396,\n",
       " 0.7806675962932208,\n",
       " 0.7691554512447879,\n",
       " 0.7578130704907171,\n",
       " 0.7466379505952441,\n",
       " 0.735627625039617,\n",
       " 0.7247796636776989,\n",
       " 0.7140916721995971,\n",
       " 0.703561291603203,\n",
       " 0.6931861976735241,\n",
       " 0.6829641004696942,\n",
       " 0.6728927438195503,\n",
       " 0.6629699048216586,\n",
       " 0.6531933933546885,\n",
       " 0.6435610515940181,\n",
       " 0.6340707535354707,\n",
       " 0.6247204045260726,\n",
       " 0.6155079408017315,\n",
       " 0.6064313290317326,\n",
       " 0.5974885658699514,\n",
       " 0.588677677512685,\n",
       " 0.5799967192630036,\n",
       " 0.5714437751015258,\n",
       " 0.5630169572635251,\n",
       " 0.5547144058222704,\n",
       " 0.5465342882785127,\n",
       " 0.5384747991560244,\n",
       " 0.5305341596031031,\n",
       " 0.5227106169999521,\n",
       " 0.5150024445718511,\n",
       " 0.5074079410080298,\n",
       " 0.4999254300861634,\n",
       " 0.4925532603024051,\n",
       " 0.4852898045068733,\n",
       " 0.47813345954451575,\n",
       " 0.47108264590126814,\n",
       " 0.464135807355432,\n",
       " 0.4572914106341925,\n",
       " 0.4505479450752018,\n",
       " 0.4439039222931534,\n",
       " 0.4373578758512723,\n",
       " 0.4309083609376506,\n",
       " 0.42455395404635504,\n",
       " 0.4182932526632383,\n",
       " 0.4121248749563822,\n",
       " 0.40604745947110676,\n",
       " 0.4000596648294763,\n",
       " 0.394160169434237,\n",
       " 0.38834767117712027,\n",
       " 0.38262088715144776,\n",
       " 0.37697855336897435,\n",
       " 0.3714194244809066,\n",
       " 0.3659422735030355,\n",
       " 0.36054589154492234,\n",
       " 0.35522908754307836,\n",
       " 0.34999068799807864,\n",
       " 0.3448295367155534,\n",
       " 0.3397444945509976,\n",
       " 0.33473443915834544,\n",
       " 0.3297982647422508,\n",
       " 0.3249348818140214,\n",
       " 0.32014321695115266,\n",
       " 0.3154222125604064,\n",
       " 0.3107708266443844,\n",
       " 0.3061880325715435,\n",
       " 0.30167281884960234,\n",
       " 0.29722418890229013,\n",
       " 0.29284116084938655,\n",
       " 0.28852276729000614,\n",
       " 0.28426805508907826,\n",
       " 0.2800760851669755,\n",
       " 0.2759459322922449,\n",
       " 0.27187668487739486,\n",
       " 0.26786744477769425,\n",
       " 0.2639173270929381,\n",
       " 0.2600254599721367,\n",
       " 0.2561909844210849,\n",
       " 0.2524130541127689,\n",
       " 0.24869083520056914,\n",
       " 0.24502350613421764,\n",
       " 0.24141025747846936,\n",
       " 0.23785029173444758,\n",
       " 0.23434282316362376,\n",
       " 0.2308870776143931,\n",
       " 0.22748229235120743,\n",
       " 0.2241277158862282,\n",
       " 0.22082260781346136,\n",
       " 0.21756623864533853,\n",
       " 0.21435788965170827,\n",
       " 0.21119685270120114,\n",
       " 0.2080824301049345,\n",
       " 0.20501393446252197,\n",
       " 0.20199068851035362,\n",
       " 0.19901202497211365,\n",
       " 0.19607728641150252,\n",
       " 0.19318582508713045,\n",
       " 0.19033700280955135,\n",
       " 0.1875301908004046,\n",
       " 0.18476476955363405,\n",
       " 0.18204012869875372,\n",
       " 0.17935566686612975,\n",
       " 0.17671079155424887,\n",
       " 0.17410491899894454,\n",
       " 0.17153747404455105,\n",
       " 0.16900789001695812,\n",
       " 0.1665156085985373,\n",
       " 0.16406007970491274,\n",
       " 0.16164076136354916,\n",
       " 0.1592571195941303,\n",
       " 0.15690862829070157,\n",
       " 0.15459476910555006,\n",
       " 0.15231503133479773,\n",
       " 0.150068911805681,\n",
       " 0.14785591476549312,\n",
       " 0.1456755517721638,\n",
       " 0.14352734158645275,\n",
       " 0.14141081006573286,\n",
       " 0.13932549005933967,\n",
       " 0.1372709213054642,\n",
       " 0.13524665032956606,\n",
       " 0.13325223034428482,\n",
       " 0.13128722115082725,\n",
       " 0.1293511890418087,\n",
       " 0.1274437067055273,\n",
       " 0.12556435313164985,\n",
       " 0.12371271351828836,\n",
       " 0.12188837918044705,\n",
       " 0.12009094745981924,\n",
       " 0.11832002163591465,\n",
       " 0.11657521083849716,\n",
       " 0.11485612996131371,\n",
       " 0.11316239957709565,\n",
       " 0.11149364585381322,\n",
       " 0.10984950047216527,\n",
       " 0.10822960054428549,\n",
       " 0.1066335885336476,\n",
       " 0.10506111217615167,\n",
       " 0.10351182440237394,\n",
       " 0.10198538326096339,\n",
       " 0.10048145184316792,\n",
       " 0.09899969820847344,\n",
       " 0.09753979531133954,\n",
       " 0.09610142092901557,\n",
       " 0.0946842575904212,\n",
       " 0.09328799250607574,\n",
       " 0.09191231749906073,\n",
       " 0.0905569289370006,\n",
       " 0.0892215276650464,\n",
       " 0.08790581893984782,\n",
       " 0.0866095123644988,\n",
       " 0.08533232182444254,\n",
       " 0.08407396542432168,\n",
       " 0.08283416542575969,\n",
       " 0.08161264818605982,\n",
       " 0.08040914409780794,\n",
       " 0.0792233875293662,\n",
       " 0.07805511676624396,\n",
       " 0.07690407395333354,\n",
       " 0.07577000503799756,\n",
       " 0.07465265971399582,\n",
       " 0.0735517913662387,\n",
       " 0.07246715701635571,\n",
       " 0.07139851726906625,\n",
       " 0.07034563625934158,\n",
       " 0.06930828160034574,\n",
       " 0.06828622433214433,\n",
       " 0.06727923887116945,\n",
       " 0.06628710296043011,\n",
       " 0.06530959762045663,\n",
       " 0.06434650710096862,\n",
       " 0.06339761883325559,\n",
       " 0.06246272338325977,\n",
       " 0.06154161440535089,\n",
       " 0.06063408859678252,\n",
       " 0.059739945652820085,\n",
       " 0.05885898822253058,\n",
       " 0.05799102186522416,\n",
       " 0.05713585500753822,\n",
       " 0.05629329890115417,\n",
       " 0.055463167581137826,\n",
       " 0.05464527782489414,\n",
       " 0.053839449111727194,\n",
       " 0.05304550358299651,\n",
       " 0.05226326600286099,\n",
       " 0.05149256371960165,\n",
       " 0.05073322662751478,\n",
       " 0.04998508712936709,\n",
       " 0.04924798009940438,\n",
       " 0.04852174284690577,\n",
       " 0.04780621508027545,\n",
       " 0.04710123887166386,\n",
       " 0.04640665862211061,\n",
       " 0.04572232102720141,\n",
       " 0.04504807504323148,\n",
       " 0.04438377185386792,\n",
       " 0.04372926483730364,\n",
       " 0.04308440953389574,\n",
       " 0.04244906361428106,\n",
       " 0.04182308684796193,\n",
       " 0.04120634107235514,\n",
       " 0.04059869016229741,\n",
       " 0.040000000000000466,\n",
       " 0.039410138445449196,\n",
       " 0.03882897530723636,\n",
       " 0.038256382313827386,\n",
       " 0.03769223308524884,\n",
       " 0.037136403105194504,\n",
       " 0.036588769693542696,\n",
       " 0.03604921197927891,\n",
       " 0.03551761087381777,\n",
       " 0.03499384904471835,\n",
       " 0.034477810889787096,\n",
       " 0.033969382511562736,\n",
       " 0.03346845169217732,\n",
       " 0.03297490786858802,\n",
       " 0.03248864210817427,\n",
       " 0.032009547084694584,\n",
       " 0.03153751705459809,\n",
       " 0.031072447833685284,\n",
       " 0.030614236774113016,\n",
       " 0.030162782741738545,\n",
       " 0.029717986093797697,\n",
       " 0.029279748656912186,\n",
       " 0.02884797370542127,\n",
       " 0.028422565940032927,\n",
       " 0.028003431466789835,\n",
       " 0.027590477776345577,\n",
       " 0.027183613723546392,\n",
       " 0.026782749507314085,\n",
       " 0.02638779665082555,\n",
       " 0.025998667981984584,\n",
       " 0.025615277614181694,\n",
       " 0.02523754092733761,\n",
       " 0.024865374549226344,\n",
       " 0.02449869633707369,\n",
       " 0.02413742535942705,\n",
       " 0.02378148187829263,\n",
       " 0.02343078733153607,\n",
       " 0.023085264315542572,\n",
       " 0.02274483656813275,\n",
       " 0.02240942895173042,\n",
       " 0.02207896743677857,\n",
       " 0.021753379085399947,\n",
       " 0.021432592035298525,\n",
       " 0.021116535483898417,\n",
       " 0.020805139672716685,\n",
       " 0.020498335871966564,\n",
       " 0.02019605636538776,\n",
       " 0.019898234435300446,\n",
       " 0.01960480434787965,\n",
       " 0.019315701338646806,\n",
       " 0.019030861598175252,\n",
       " 0.018750222258006512,\n",
       " 0.018473721376774277,\n",
       " 0.018201297926533,\n",
       " 0.017932891779288113,\n",
       " 0.01766844369372485,\n",
       " 0.017407895302132798,\n",
       " 0.017151189097523258,\n",
       " 0.016898268420936564,\n",
       " 0.016649077448936605,\n",
       " 0.01640356118128975,\n",
       " 0.016161665428825443,\n",
       " 0.015923336801475833,\n",
       " 0.015688522696491784,\n",
       " 0.015457171286832648,\n",
       " 0.015229231509727242,\n",
       " 0.015004653055403522,\n",
       " 0.014783386355984455,\n",
       " 0.014565382574547628,\n",
       " 0.014350593594346215,\n",
       " 0.014138972008188852,\n",
       " 0.013930471107976175,\n",
       " 0.013725044874391619,\n",
       " 0.013522647966744253,\n",
       " 0.013323235712961424,\n",
       " 0.013126764099728913,\n",
       " 0.012933189762776567,\n",
       " 0.01274246997730712,\n",
       " 0.012554562648566192,\n",
       " 0.012369426302551327,\n",
       " 0.012187020076858072,\n",
       " 0.012007303711660998,\n",
       " 0.011830237540827758,\n",
       " 0.011655782483164174,\n",
       " 0.011483900033788408,\n",
       " 0.011314552255632365,\n",
       " 0.011147701771068393,\n",
       " 0.010983311753659486,\n",
       " 0.010821345920031117,\n",
       " 0.010661768521862954,\n",
       " 0.010504544337998658,\n",
       " 0.010349638666672042,\n",
       " 0.010197017317847867,\n",
       " 0.010046646605675568,\n",
       " 0.009898493341054294,\n",
       " 0.009752524824307553,\n",
       " 0.009608708837965907,\n",
       " 0.009467013639656081,\n",
       " 0.009327407955094942,\n",
       " 0.009189860971186788,\n",
       " 0.009054342329222432,\n",
       " 0.00892082211817857,\n",
       " 0.008789270868115966,\n",
       " 0.00865965954367499,\n",
       " 0.008531959537667071,\n",
       " 0.00840614266476065,\n",
       " 0.008282181155260264,\n",
       " 0.008160047648977339,\n",
       " 0.008039715189191384,\n",
       " 0.00792115721670024,\n",
       " 0.007804347563958045,\n",
       " 0.007689260449299678,\n",
       " 0.007575870471250341,\n",
       " 0.007464152602919072,\n",
       " 0.007354082186474929,\n",
       " 0.007245634927704633,\n",
       " 0.0071387868906504625,\n",
       " 0.0070335144923272305,\n",
       " 0.006929794497517156,\n",
       " 0.006827604013641499,\n",
       " 0.006726920485707823,\n",
       " 0.006627721691331764,\n",
       " 0.006529985735832211,\n",
       " 0.006433691047398822,\n",
       " 0.006338816372330791,\n",
       " 0.0062453407703458395,\n",
       " 0.006153243609958375,\n",
       " 0.006062504563925808,\n",
       " 0.005973103604762022,\n",
       " 0.005885021000317006,\n",
       " 0.00579823730942166,\n",
       " 0.005712733377596845,\n",
       " 0.0056284903328256905,\n",
       " 0.005545489581388256,\n",
       " 0.0054637128037576185,\n",
       " 0.005383141950556466,\n",
       " 0.005303759238573331,\n",
       " 0.005225547146837569,\n",
       " 0.005148488412752205,\n",
       " 0.0050725660282838255,\n",
       " 0.00499776323620864,\n",
       " 0.004924063526413909,\n",
       " 0.004851450632253918,\n",
       " 0.004779908526959667,\n",
       " 0.004709421420101535,\n",
       " 0.0046399737541040825,\n",
       " 0.00457155020081226,\n",
       " 0.004504135658108253,\n",
       " 0.004437715246578215,\n",
       " 0.004372274306228153,\n",
       " 0.0043077983932482454,\n",
       " 0.0042442732768248745,\n",
       " 0.004181684935999666,\n",
       " 0.004120019556574857,\n",
       " 0.0040592635280642855,\n",
       " 0.003999403440689354,\n",
       " 0.003940426082419287,\n",
       " 0.0038823184360550324,\n",
       " 0.0038250676763561704,\n",
       " 0.0037686611672101892,\n",
       " 0.0037130864588434996,\n",
       " 0.0036583312850735827,\n",
       " 0.003604383560601657,\n",
       " 0.003551231378345269,\n",
       " 0.0034988630068102195,\n",
       " 0.003447266887501245,\n",
       " 0.00339643163237088,\n",
       " 0.0033463460213059458,\n",
       " 0.003296998999651096,\n",
       " 0.0032483796757688923,\n",
       " 0.0032004773186358484,\n",
       " 0.003153281355473933,\n",
       " 0.003106781369416998,\n",
       " 0.0030609670972116176,\n",
       " 0.00301582842695183,\n",
       " 0.0029713553958472874,\n",
       " 0.0029275381880243183,\n",
       " 0.0028843671323594126,\n",
       " 0.00284183270034466,\n",
       " 0.002799925503984662,\n",
       " 0.0027586362937244593,\n",
       " 0.002717955956408013,\n",
       " 0.002677875513266795,\n",
       " 0.0026383861179380373,\n",
       " 0.002599479054512202,\n",
       " 0.0025611457356092514,\n",
       " 0.002523377700483281,\n",
       " 0.0024861666131551045,\n",
       " 0.002449504260572376,\n",
       " 0.002413382550796847,\n",
       " 0.002377793511218349,\n",
       " 0.0023427292867951198,\n",
       " 0.002308182138320076,\n",
       " 0.0022741444407126526,\n",
       " 0.0022406086813358305,\n",
       " 0.0022075674583379853,\n",
       " 0.0021750134790191845,\n",
       " 0.002142939558221579,\n",
       " 0.0021113386167435294,\n",
       " 0.002080203679777118,\n",
       " 0.002049527875368703,\n",
       " 0.0020193044329021746,\n",
       " 0.0019895266816045763,\n",
       " 0.001960188049073764,\n",
       " 0.0019312820598277776,\n",
       " 0.0019028023338756028,\n",
       " 0.001874742585309012,\n",
       " 0.0018470966209151662,\n",
       " 0.001819858338809681,\n",
       " 0.001793021727089847,\n",
       " 0.0017665808625077115,\n",
       " 0.0017405299091627288,\n",
       " 0.0017148631172136863,\n",
       " 0.001689574821609629,\n",
       " 0.0016646594408394955,\n",
       " 0.001640111475700195,\n",
       " 0.0016159255080828478,\n",
       " 0.001592096199776928,\n",
       " 0.0015686182912920386,\n",
       " 0.0015454866006970617,\n",
       " 0.0015226960224764285,\n",
       " 0.0015002415264032544,\n",
       " 0.0014781181564290898,\n",
       " 0.001456321029590047,\n",
       " 0.0014348453349290547,\n",
       " 0.0014136863324340076,\n",
       " 0.0013928393519915727,\n",
       " 0.0013722997923564244,\n",
       " 0.001352063120135681,\n",
       " 0.0013321248687883144,\n",
       " 0.0013124806376393176,\n",
       " 0.0012931260909084083,\n",
       " 0.0012740569567530574,\n",
       " 0.001255269026325627,\n",
       " 0.001236758152844415,\n",
       " 0.001218520250678396,\n",
       " 0.0012005512944454622,\n",
       " 0.0011828473181239587,\n",
       " 0.001165404414177324,\n",
       " 0.0011482187326916353,\n",
       " 0.001131286480525876,\n",
       " 0.0011146039204747305,\n",
       " 0.0010981673704437264,\n",
       " 0.0010819732026365412,\n",
       " 0.0010660178427542913,\n",
       " 0.0010502977692066302,\n",
       " 0.0010348095123344815,\n",
       " 0.0010195496536442301,\n",
       " 0.0010045148250532104,\n",
       " 0.0009897017081463187,\n",
       " 0.0009751070334435878,\n",
       " 0.0009607275796785651,\n",
       " 0.0009465601730873283,\n",
       " 0.0009326016867079881,\n",
       " 0.0009188490396905205,\n",
       " 0.0009052991966167758,\n",
       " 0.0008919491668305163,\n",
       " 0.0008787960037773323,\n",
       " 0.0008658368043542939,\n",
       " 0.0008530687082691909,\n",
       " 0.0008404888974092232,\n",
       " 0.0008280945952190012,\n",
       " 0.0008158830660877166,\n",
       " 0.0008038516147453528,\n",
       " 0.0007919975856677968,\n",
       " 0.0007803183624907255,\n",
       " 0.0007688113674321334,\n",
       " 0.0007574740607233784,\n",
       " 0.0007463039400486146,\n",
       " 0.0007352985399924944,\n",
       " 0.0007244554314960132,\n",
       " 0.0007137722213203797,\n",
       " 0.0007032465515187907,\n",
       " 0.0006928760989159986,\n",
       " 0.0006826585745955484,\n",
       " 0.0006725917233945814,\n",
       " 0.0006626733234060853,\n",
       " 0.0006529011854884861,\n",
       " 0.0006432731527824711,\n",
       " 0.0006337871002349369,\n",
       " 0.000624440934129959,\n",
       " 0.0006152325916266754,\n",
       " 0.0006061600403039877,\n",
       " 0.0005972212777119734,\n",
       " 0.0005884143309299165,\n",
       " 0.0005797372561308524,\n",
       " 0.0005711881381525366,\n",
       " 0.0005627650900747392,\n",
       " 0.0005544662528027725,\n",
       " 0.0005462897946571611,\n",
       " 0.000538233910969362,\n",
       " 0.0005302968236834471,\n",
       " 0.0005224767809636591,\n",
       " 0.000514772056807755,\n",
       " 0.0005071809506660506,\n",
       " 0.000499701787066084,\n",
       " 0.0004923329152428129,\n",
       " 0.00048507270877426586,\n",
       " 0.0004779195652225663,\n",
       " 0.0004708719057802501,\n",
       " 0.00046392817492179873,\n",
       " 0.00045708684006031113,\n",
       " 0.00045034639120923863,\n",
       " 0.00044370534064910774,\n",
       " 0.00043716222259915824,\n",
       " 0.0004307155928938226,\n",
       " 0.0004243640286639771,\n",
       " 0.0004181061280228928,\n",
       " 0.000411940509756818,\n",
       " 0.00040586581302012306,\n",
       " 0.00039988069703494146,\n",
       " 0.0003939838407952396,\n",
       " 0.0003881739427752506,\n",
       " 0.00038244972064220805,\n",
       " 0.0003768099109733153,\n",
       " 0.00037125326897688926,\n",
       " 0.00036577856821761557,\n",
       " 0.0003603846003458561,\n",
       " 0.0003550701748309475,\n",
       " 0.0003498341186984332,\n",
       " 0.0003446752762711699,\n",
       " 0.0003395925089142525,\n",
       " 0.00033458469478369934,\n",
       " 0.000329650728578845,\n",
       " 0.0003247895212983831]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1e48314-674c-4d71-94be-fbb2df7c3355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134226318ef54a3c9d9a3e52914d3d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating target network...\n",
      "EPISODE: 1 - FINAL SCORE: 13 - Temperature: 5.0\n",
      "EPISODE: 2 - FINAL SCORE: 28 - Temperature: 4.926267305681092\n",
      "EPISODE: 3 - FINAL SCORE: 23 - Temperature: 4.8536219134044885\n",
      "EPISODE: 4 - FINAL SCORE: 19 - Temperature: 4.7820477892283675\n",
      "EPISODE: 5 - FINAL SCORE: 20 - Temperature: 4.7115291356560505\n",
      "EPISODE: 6 - FINAL SCORE: 17 - Temperature: 4.642050388149259\n",
      "EPISODE: 7 - FINAL SCORE: 41 - Temperature: 4.573596211692783\n",
      "EPISODE: 8 - FINAL SCORE: 14 - Temperature: 4.506151497409811\n",
      "EPISODE: 9 - FINAL SCORE: 20 - Temperature: 4.439701359227169\n",
      "EPISODE: 10 - FINAL SCORE: 10 - Temperature: 4.374231130589742\n",
      "Updating target network...\n",
      "EPISODE: 11 - FINAL SCORE: 14 - Temperature: 4.309726361223337\n",
      "EPISODE: 12 - FINAL SCORE: 54 - Temperature: 4.246172813945293\n",
      "EPISODE: 13 - FINAL SCORE: 11 - Temperature: 4.183556461522116\n",
      "EPISODE: 14 - FINAL SCORE: 22 - Temperature: 4.1218634835734544\n",
      "EPISODE: 15 - FINAL SCORE: 14 - Temperature: 4.0610802635217365\n",
      "EPISODE: 16 - FINAL SCORE: 13 - Temperature: 4.0011933855867765\n",
      "EPISODE: 17 - FINAL SCORE: 19 - Temperature: 3.942189631824715\n",
      "EPISODE: 18 - FINAL SCORE: 30 - Temperature: 3.884055979210615\n",
      "EPISODE: 19 - FINAL SCORE: 39 - Temperature: 3.8267795967640823\n",
      "EPISODE: 20 - FINAL SCORE: 15 - Temperature: 3.7703478427172743\n",
      "Updating target network...\n",
      "EPISODE: 21 - FINAL SCORE: 38 - Temperature: 3.7147482617246688\n",
      "EPISODE: 22 - FINAL SCORE: 47 - Temperature: 3.6599685821139802\n",
      "EPISODE: 23 - FINAL SCORE: 17 - Temperature: 3.6059967131776167\n",
      "EPISODE: 24 - FINAL SCORE: 14 - Temperature: 3.5528207425040743\n",
      "EPISODE: 25 - FINAL SCORE: 17 - Temperature: 3.5004289333486884\n",
      "EPISODE: 26 - FINAL SCORE: 16 - Temperature: 3.448809722043156\n",
      "EPISODE: 27 - FINAL SCORE: 23 - Temperature: 3.3979517154432592\n",
      "EPISODE: 28 - FINAL SCORE: 15 - Temperature: 3.3478436884142218\n",
      "EPISODE: 29 - FINAL SCORE: 17 - Temperature: 3.298474581353155\n",
      "EPISODE: 30 - FINAL SCORE: 25 - Temperature: 3.2498334977480345\n",
      "Updating target network...\n",
      "EPISODE: 31 - FINAL SCORE: 27 - Temperature: 3.2019097017726743\n",
      "EPISODE: 32 - FINAL SCORE: 15 - Temperature: 3.154692615917164\n",
      "EPISODE: 33 - FINAL SCORE: 35 - Temperature: 3.1081718186532563\n",
      "EPISODE: 34 - FINAL SCORE: 27 - Temperature: 3.0623370421341756\n",
      "EPISODE: 35 - FINAL SCORE: 18 - Temperature: 3.0171781699283455\n",
      "EPISODE: 36 - FINAL SCORE: 16 - Temperature: 2.9726852347865442\n",
      "EPISODE: 37 - FINAL SCORE: 13 - Temperature: 2.928848416441974\n",
      "EPISODE: 38 - FINAL SCORE: 17 - Temperature: 2.885658039442787\n",
      "EPISODE: 39 - FINAL SCORE: 33 - Temperature: 2.8431045710165606\n",
      "EPISODE: 40 - FINAL SCORE: 17 - Temperature: 2.8011786189662695\n",
      "Updating target network...\n",
      "EPISODE: 41 - FINAL SCORE: 74 - Temperature: 2.7598709295972896\n",
      "EPISODE: 42 - FINAL SCORE: 58 - Temperature: 2.7191723856749617\n",
      "EPISODE: 43 - FINAL SCORE: 22 - Temperature: 2.679074004412284\n",
      "EPISODE: 44 - FINAL SCORE: 18 - Temperature: 2.6395669354872715\n",
      "EPISODE: 45 - FINAL SCORE: 42 - Temperature: 2.600642459089555\n",
      "EPISODE: 46 - FINAL SCORE: 12 - Temperature: 2.5622919839957903\n",
      "EPISODE: 47 - FINAL SCORE: 11 - Temperature: 2.5245070456734404\n",
      "EPISODE: 48 - FINAL SCORE: 15 - Temperature: 2.4872793044125263\n",
      "EPISODE: 49 - FINAL SCORE: 24 - Temperature: 2.4506005434849274\n",
      "EPISODE: 50 - FINAL SCORE: 17 - Temperature: 2.4144626673308225\n",
      "Updating target network...\n",
      "EPISODE: 51 - FINAL SCORE: 29 - Temperature: 2.3788576997718787\n",
      "EPISODE: 52 - FINAL SCORE: 21 - Temperature: 2.3437777822507866\n",
      "EPISODE: 53 - FINAL SCORE: 15 - Temperature: 2.3092151720967573\n",
      "EPISODE: 54 - FINAL SCORE: 17 - Temperature: 2.2751622408165986\n",
      "EPISODE: 55 - FINAL SCORE: 18 - Temperature: 2.241611472410988\n",
      "EPISODE: 56 - FINAL SCORE: 17 - Temperature: 2.2085554617155805\n",
      "EPISODE: 57 - FINAL SCORE: 20 - Temperature: 2.1759869127665743\n",
      "EPISODE: 58 - FINAL SCORE: 8 - Temperature: 2.143898637190382\n",
      "EPISODE: 59 - FINAL SCORE: 55 - Temperature: 2.1122835526170456\n",
      "EPISODE: 60 - FINAL SCORE: 14 - Temperature: 2.0811346811170512\n",
      "Updating target network...\n",
      "EPISODE: 61 - FINAL SCORE: 11 - Temperature: 2.050445147661195\n",
      "EPISODE: 62 - FINAL SCORE: 18 - Temperature: 2.0202081786031565\n",
      "EPISODE: 63 - FINAL SCORE: 13 - Temperature: 1.990417100184456\n",
      "EPISODE: 64 - FINAL SCORE: 35 - Temperature: 1.9610653370614504\n",
      "EPISODE: 65 - FINAL SCORE: 24 - Temperature: 1.9321464108540585\n",
      "EPISODE: 66 - FINAL SCORE: 13 - Temperature: 1.903653938715883\n",
      "EPISODE: 67 - FINAL SCORE: 14 - Temperature: 1.8755816319254182\n",
      "EPISODE: 68 - FINAL SCORE: 11 - Temperature: 1.847923294498035\n",
      "EPISODE: 69 - FINAL SCORE: 47 - Temperature: 1.8206728218184323\n",
      "EPISODE: 70 - FINAL SCORE: 10 - Temperature: 1.7938241992932558\n",
      "Updating target network...\n",
      "EPISODE: 71 - FINAL SCORE: 51 - Temperature: 1.767371501023586\n",
      "EPISODE: 72 - FINAL SCORE: 64 - Temperature: 1.7413088884970016\n",
      "EPISODE: 73 - FINAL SCORE: 12 - Temperature: 1.7156306092989322\n",
      "EPISODE: 74 - FINAL SCORE: 15 - Temperature: 1.6903309958430122\n",
      "EPISODE: 75 - FINAL SCORE: 8 - Temperature: 1.6654044641201584\n",
      "EPISODE: 76 - FINAL SCORE: 11 - Temperature: 1.640845512466095\n",
      "EPISODE: 77 - FINAL SCORE: 19 - Temperature: 1.6166487203470519\n",
      "EPISODE: 78 - FINAL SCORE: 19 - Temperature: 1.5928087471633714\n",
      "EPISODE: 79 - FINAL SCORE: 26 - Temperature: 1.5693203310707555\n",
      "EPISODE: 80 - FINAL SCORE: 11 - Temperature: 1.5461782878188979\n",
      "Updating target network...\n",
      "EPISODE: 81 - FINAL SCORE: 13 - Temperature: 1.523377509607241\n",
      "EPISODE: 82 - FINAL SCORE: 28 - Temperature: 1.500912963957607\n",
      "EPISODE: 83 - FINAL SCORE: 16 - Temperature: 1.4787796926034524\n",
      "EPISODE: 84 - FINAL SCORE: 24 - Temperature: 1.4569728103955046\n",
      "EPISODE: 85 - FINAL SCORE: 10 - Temperature: 1.4354875042235342\n",
      "EPISODE: 86 - FINAL SCORE: 18 - Temperature: 1.4143190319540289\n",
      "EPISODE: 87 - FINAL SCORE: 35 - Temperature: 1.3934627213835329\n",
      "EPISODE: 88 - FINAL SCORE: 25 - Temperature: 1.3729139692074197\n",
      "EPISODE: 89 - FINAL SCORE: 20 - Temperature: 1.3526682400038736\n",
      "EPISODE: 90 - FINAL SCORE: 9 - Temperature: 1.3327210652328536\n",
      "Updating target network...\n",
      "EPISODE: 91 - FINAL SCORE: 32 - Temperature: 1.3130680422498167\n",
      "EPISODE: 92 - FINAL SCORE: 23 - Temperature: 1.2937048333339902\n",
      "EPISODE: 93 - FINAL SCORE: 17 - Temperature: 1.2746271647309684\n",
      "EPISODE: 94 - FINAL SCORE: 34 - Temperature: 1.2558308257094315\n",
      "EPISODE: 95 - FINAL SCORE: 25 - Temperature: 1.2373116676317724\n",
      "EPISODE: 96 - FINAL SCORE: 11 - Temperature: 1.21906560303843\n",
      "EPISODE: 97 - FINAL SCORE: 13 - Temperature: 1.201088604745724\n",
      "EPISODE: 98 - FINAL SCORE: 16 - Temperature: 1.1833767049569963\n",
      "EPISODE: 99 - FINAL SCORE: 42 - Temperature: 1.165925994386854\n",
      "EPISODE: 100 - FINAL SCORE: 10 - Temperature: 1.1487326213983349\n",
      "Updating target network...\n",
      "EPISODE: 101 - FINAL SCORE: 63 - Temperature: 1.1317927911527907\n",
      "EPISODE: 102 - FINAL SCORE: 39 - Temperature: 1.1151027647723082\n",
      "EPISODE: 103 - FINAL SCORE: 9 - Temperature: 1.098658858514483\n",
      "EPISODE: 104 - FINAL SCORE: 16 - Temperature: 1.0824574429593612\n",
      "EPISODE: 105 - FINAL SCORE: 15 - Temperature: 1.0664949422083712\n",
      "EPISODE: 106 - FINAL SCORE: 16 - Temperature: 1.050767833095069\n",
      "EPISODE: 107 - FINAL SCORE: 21 - Temperature: 1.0352726444075209\n",
      "EPISODE: 108 - FINAL SCORE: 74 - Temperature: 1.0200059561221555\n",
      "EPISODE: 109 - FINAL SCORE: 16 - Temperature: 1.0049643986489114\n",
      "EPISODE: 110 - FINAL SCORE: 21 - Temperature: 0.9901446520875183\n",
      "Updating target network...\n",
      "EPISODE: 111 - FINAL SCORE: 17 - Temperature: 0.9755434454947441\n",
      "EPISODE: 112 - FINAL SCORE: 12 - Temperature: 0.9611575561624485\n",
      "EPISODE: 113 - FINAL SCORE: 10 - Temperature: 0.9469838089062815\n",
      "EPISODE: 114 - FINAL SCORE: 14 - Temperature: 0.933019075364873\n",
      "EPISODE: 115 - FINAL SCORE: 10 - Temperature: 0.9192602733093553\n",
      "EPISODE: 116 - FINAL SCORE: 18 - Temperature: 0.9057043659630684\n",
      "EPISODE: 117 - FINAL SCORE: 34 - Temperature: 0.8923483613312972\n",
      "EPISODE: 118 - FINAL SCORE: 28 - Temperature: 0.8791893115408934\n",
      "EPISODE: 119 - FINAL SCORE: 19 - Temperature: 0.8662243121896342\n",
      "EPISODE: 120 - FINAL SCORE: 24 - Temperature: 0.8534505017051773\n",
      "Updating target network...\n",
      "EPISODE: 121 - FINAL SCORE: 18 - Temperature: 0.8408650607134681\n",
      "EPISODE: 122 - FINAL SCORE: 19 - Temperature: 0.8284652114164608\n",
      "EPISODE: 123 - FINAL SCORE: 14 - Temperature: 0.8162482169790168\n",
      "EPISODE: 124 - FINAL SCORE: 9 - Temperature: 0.8042113809248432\n",
      "EPISODE: 125 - FINAL SCORE: 22 - Temperature: 0.7923520465413396\n",
      "EPISODE: 126 - FINAL SCORE: 16 - Temperature: 0.7806675962932208\n",
      "EPISODE: 127 - FINAL SCORE: 16 - Temperature: 0.7691554512447879\n",
      "EPISODE: 128 - FINAL SCORE: 42 - Temperature: 0.7578130704907171\n",
      "EPISODE: 129 - FINAL SCORE: 26 - Temperature: 0.7466379505952441\n",
      "EPISODE: 130 - FINAL SCORE: 32 - Temperature: 0.735627625039617\n",
      "Updating target network...\n",
      "EPISODE: 131 - FINAL SCORE: 13 - Temperature: 0.7247796636776989\n",
      "EPISODE: 132 - FINAL SCORE: 16 - Temperature: 0.7140916721995971\n",
      "EPISODE: 133 - FINAL SCORE: 19 - Temperature: 0.703561291603203\n",
      "EPISODE: 134 - FINAL SCORE: 17 - Temperature: 0.6931861976735241\n",
      "EPISODE: 135 - FINAL SCORE: 14 - Temperature: 0.6829641004696942\n",
      "EPISODE: 136 - FINAL SCORE: 21 - Temperature: 0.6728927438195503\n",
      "EPISODE: 137 - FINAL SCORE: 15 - Temperature: 0.6629699048216586\n",
      "EPISODE: 138 - FINAL SCORE: 29 - Temperature: 0.6531933933546885\n",
      "EPISODE: 139 - FINAL SCORE: 32 - Temperature: 0.6435610515940181\n",
      "EPISODE: 140 - FINAL SCORE: 20 - Temperature: 0.6340707535354707\n",
      "Updating target network...\n",
      "EPISODE: 141 - FINAL SCORE: 26 - Temperature: 0.6247204045260726\n",
      "EPISODE: 142 - FINAL SCORE: 40 - Temperature: 0.6155079408017315\n",
      "EPISODE: 143 - FINAL SCORE: 10 - Temperature: 0.6064313290317326\n",
      "EPISODE: 144 - FINAL SCORE: 14 - Temperature: 0.5974885658699514\n",
      "EPISODE: 145 - FINAL SCORE: 13 - Temperature: 0.588677677512685\n",
      "EPISODE: 146 - FINAL SCORE: 54 - Temperature: 0.5799967192630036\n",
      "EPISODE: 147 - FINAL SCORE: 22 - Temperature: 0.5714437751015258\n",
      "EPISODE: 148 - FINAL SCORE: 14 - Temperature: 0.5630169572635251\n",
      "EPISODE: 149 - FINAL SCORE: 17 - Temperature: 0.5547144058222704\n",
      "EPISODE: 150 - FINAL SCORE: 13 - Temperature: 0.5465342882785127\n",
      "Updating target network...\n",
      "EPISODE: 151 - FINAL SCORE: 10 - Temperature: 0.5384747991560244\n",
      "EPISODE: 152 - FINAL SCORE: 22 - Temperature: 0.5305341596031031\n",
      "EPISODE: 153 - FINAL SCORE: 32 - Temperature: 0.5227106169999521\n",
      "EPISODE: 154 - FINAL SCORE: 24 - Temperature: 0.5150024445718511\n",
      "EPISODE: 155 - FINAL SCORE: 14 - Temperature: 0.5074079410080298\n",
      "EPISODE: 156 - FINAL SCORE: 13 - Temperature: 0.4999254300861634\n",
      "EPISODE: 157 - FINAL SCORE: 12 - Temperature: 0.4925532603024051\n",
      "EPISODE: 158 - FINAL SCORE: 44 - Temperature: 0.4852898045068733\n",
      "EPISODE: 159 - FINAL SCORE: 10 - Temperature: 0.47813345954451575\n",
      "EPISODE: 160 - FINAL SCORE: 12 - Temperature: 0.47108264590126814\n",
      "Updating target network...\n",
      "EPISODE: 161 - FINAL SCORE: 16 - Temperature: 0.464135807355432\n",
      "EPISODE: 162 - FINAL SCORE: 16 - Temperature: 0.4572914106341925\n",
      "EPISODE: 163 - FINAL SCORE: 12 - Temperature: 0.4505479450752018\n",
      "EPISODE: 164 - FINAL SCORE: 23 - Temperature: 0.4439039222931534\n",
      "EPISODE: 165 - FINAL SCORE: 10 - Temperature: 0.4373578758512723\n",
      "EPISODE: 166 - FINAL SCORE: 15 - Temperature: 0.4309083609376506\n",
      "EPISODE: 167 - FINAL SCORE: 24 - Temperature: 0.42455395404635504\n",
      "EPISODE: 168 - FINAL SCORE: 13 - Temperature: 0.4182932526632383\n",
      "EPISODE: 169 - FINAL SCORE: 48 - Temperature: 0.4121248749563822\n",
      "EPISODE: 170 - FINAL SCORE: 10 - Temperature: 0.40604745947110676\n",
      "Updating target network...\n",
      "EPISODE: 171 - FINAL SCORE: 43 - Temperature: 0.4000596648294763\n",
      "EPISODE: 172 - FINAL SCORE: 10 - Temperature: 0.394160169434237\n",
      "EPISODE: 173 - FINAL SCORE: 39 - Temperature: 0.38834767117712027\n",
      "EPISODE: 174 - FINAL SCORE: 12 - Temperature: 0.38262088715144776\n",
      "EPISODE: 175 - FINAL SCORE: 22 - Temperature: 0.37697855336897435\n",
      "EPISODE: 176 - FINAL SCORE: 15 - Temperature: 0.3714194244809066\n",
      "EPISODE: 177 - FINAL SCORE: 42 - Temperature: 0.3659422735030355\n",
      "EPISODE: 178 - FINAL SCORE: 18 - Temperature: 0.36054589154492234\n",
      "EPISODE: 179 - FINAL SCORE: 14 - Temperature: 0.35522908754307836\n",
      "EPISODE: 180 - FINAL SCORE: 17 - Temperature: 0.34999068799807864\n",
      "Updating target network...\n",
      "EPISODE: 181 - FINAL SCORE: 16 - Temperature: 0.3448295367155534\n",
      "EPISODE: 182 - FINAL SCORE: 8 - Temperature: 0.3397444945509976\n",
      "EPISODE: 183 - FINAL SCORE: 9 - Temperature: 0.33473443915834544\n",
      "EPISODE: 184 - FINAL SCORE: 12 - Temperature: 0.3297982647422508\n",
      "EPISODE: 185 - FINAL SCORE: 34 - Temperature: 0.3249348818140214\n",
      "EPISODE: 186 - FINAL SCORE: 30 - Temperature: 0.32014321695115266\n",
      "EPISODE: 187 - FINAL SCORE: 12 - Temperature: 0.3154222125604064\n",
      "EPISODE: 188 - FINAL SCORE: 17 - Temperature: 0.3107708266443844\n",
      "EPISODE: 189 - FINAL SCORE: 10 - Temperature: 0.3061880325715435\n",
      "EPISODE: 190 - FINAL SCORE: 52 - Temperature: 0.30167281884960234\n",
      "Updating target network...\n",
      "EPISODE: 191 - FINAL SCORE: 14 - Temperature: 0.29722418890229013\n",
      "EPISODE: 192 - FINAL SCORE: 20 - Temperature: 0.29284116084938655\n",
      "EPISODE: 193 - FINAL SCORE: 13 - Temperature: 0.28852276729000614\n",
      "EPISODE: 194 - FINAL SCORE: 15 - Temperature: 0.28426805508907826\n",
      "EPISODE: 195 - FINAL SCORE: 22 - Temperature: 0.2800760851669755\n",
      "EPISODE: 196 - FINAL SCORE: 35 - Temperature: 0.2759459322922449\n",
      "EPISODE: 197 - FINAL SCORE: 15 - Temperature: 0.27187668487739486\n",
      "EPISODE: 198 - FINAL SCORE: 11 - Temperature: 0.26786744477769425\n",
      "EPISODE: 199 - FINAL SCORE: 16 - Temperature: 0.2639173270929381\n",
      "EPISODE: 200 - FINAL SCORE: 19 - Temperature: 0.2600254599721367\n",
      "Updating target network...\n",
      "EPISODE: 201 - FINAL SCORE: 28 - Temperature: 0.2561909844210849\n",
      "EPISODE: 202 - FINAL SCORE: 12 - Temperature: 0.2524130541127689\n",
      "EPISODE: 203 - FINAL SCORE: 11 - Temperature: 0.24869083520056914\n",
      "EPISODE: 204 - FINAL SCORE: 10 - Temperature: 0.24502350613421764\n",
      "EPISODE: 205 - FINAL SCORE: 9 - Temperature: 0.24141025747846936\n",
      "EPISODE: 206 - FINAL SCORE: 9 - Temperature: 0.23785029173444758\n",
      "EPISODE: 207 - FINAL SCORE: 12 - Temperature: 0.23434282316362376\n",
      "EPISODE: 208 - FINAL SCORE: 17 - Temperature: 0.2308870776143931\n",
      "EPISODE: 209 - FINAL SCORE: 24 - Temperature: 0.22748229235120743\n",
      "EPISODE: 210 - FINAL SCORE: 22 - Temperature: 0.2241277158862282\n",
      "Updating target network...\n",
      "EPISODE: 211 - FINAL SCORE: 15 - Temperature: 0.22082260781346136\n",
      "EPISODE: 212 - FINAL SCORE: 11 - Temperature: 0.21756623864533853\n",
      "EPISODE: 213 - FINAL SCORE: 11 - Temperature: 0.21435788965170827\n",
      "EPISODE: 214 - FINAL SCORE: 13 - Temperature: 0.21119685270120114\n",
      "EPISODE: 215 - FINAL SCORE: 10 - Temperature: 0.2080824301049345\n",
      "EPISODE: 216 - FINAL SCORE: 13 - Temperature: 0.20501393446252197\n",
      "EPISODE: 217 - FINAL SCORE: 14 - Temperature: 0.20199068851035362\n",
      "EPISODE: 218 - FINAL SCORE: 16 - Temperature: 0.19901202497211365\n",
      "EPISODE: 219 - FINAL SCORE: 12 - Temperature: 0.19607728641150252\n",
      "EPISODE: 220 - FINAL SCORE: 31 - Temperature: 0.19318582508713045\n",
      "Updating target network...\n",
      "EPISODE: 221 - FINAL SCORE: 13 - Temperature: 0.19033700280955135\n",
      "EPISODE: 222 - FINAL SCORE: 13 - Temperature: 0.1875301908004046\n",
      "EPISODE: 223 - FINAL SCORE: 13 - Temperature: 0.18476476955363405\n",
      "EPISODE: 224 - FINAL SCORE: 11 - Temperature: 0.18204012869875372\n",
      "EPISODE: 225 - FINAL SCORE: 12 - Temperature: 0.17935566686612975\n",
      "EPISODE: 226 - FINAL SCORE: 12 - Temperature: 0.17671079155424887\n",
      "EPISODE: 227 - FINAL SCORE: 19 - Temperature: 0.17410491899894454\n",
      "EPISODE: 228 - FINAL SCORE: 12 - Temperature: 0.17153747404455105\n",
      "EPISODE: 229 - FINAL SCORE: 16 - Temperature: 0.16900789001695812\n",
      "EPISODE: 230 - FINAL SCORE: 15 - Temperature: 0.1665156085985373\n",
      "Updating target network...\n",
      "EPISODE: 231 - FINAL SCORE: 11 - Temperature: 0.16406007970491274\n",
      "EPISODE: 232 - FINAL SCORE: 10 - Temperature: 0.16164076136354916\n",
      "EPISODE: 233 - FINAL SCORE: 14 - Temperature: 0.1592571195941303\n",
      "EPISODE: 234 - FINAL SCORE: 10 - Temperature: 0.15690862829070157\n",
      "EPISODE: 235 - FINAL SCORE: 12 - Temperature: 0.15459476910555006\n",
      "EPISODE: 236 - FINAL SCORE: 13 - Temperature: 0.15231503133479773\n",
      "EPISODE: 237 - FINAL SCORE: 11 - Temperature: 0.150068911805681\n",
      "EPISODE: 238 - FINAL SCORE: 11 - Temperature: 0.14785591476549312\n",
      "EPISODE: 239 - FINAL SCORE: 41 - Temperature: 0.1456755517721638\n",
      "EPISODE: 240 - FINAL SCORE: 13 - Temperature: 0.14352734158645275\n",
      "Updating target network...\n",
      "EPISODE: 241 - FINAL SCORE: 11 - Temperature: 0.14141081006573286\n",
      "EPISODE: 242 - FINAL SCORE: 11 - Temperature: 0.13932549005933967\n",
      "EPISODE: 243 - FINAL SCORE: 11 - Temperature: 0.1372709213054642\n",
      "EPISODE: 244 - FINAL SCORE: 10 - Temperature: 0.13524665032956606\n",
      "EPISODE: 245 - FINAL SCORE: 16 - Temperature: 0.13325223034428482\n",
      "EPISODE: 246 - FINAL SCORE: 12 - Temperature: 0.13128722115082725\n",
      "EPISODE: 247 - FINAL SCORE: 13 - Temperature: 0.1293511890418087\n",
      "EPISODE: 248 - FINAL SCORE: 11 - Temperature: 0.1274437067055273\n",
      "EPISODE: 249 - FINAL SCORE: 10 - Temperature: 0.12556435313164985\n",
      "EPISODE: 250 - FINAL SCORE: 9 - Temperature: 0.12371271351828836\n",
      "Updating target network...\n",
      "EPISODE: 251 - FINAL SCORE: 9 - Temperature: 0.12188837918044705\n",
      "EPISODE: 252 - FINAL SCORE: 8 - Temperature: 0.12009094745981924\n",
      "EPISODE: 253 - FINAL SCORE: 13 - Temperature: 0.11832002163591465\n",
      "EPISODE: 254 - FINAL SCORE: 12 - Temperature: 0.11657521083849716\n",
      "EPISODE: 255 - FINAL SCORE: 12 - Temperature: 0.11485612996131371\n",
      "EPISODE: 256 - FINAL SCORE: 10 - Temperature: 0.11316239957709565\n",
      "EPISODE: 257 - FINAL SCORE: 13 - Temperature: 0.11149364585381322\n",
      "EPISODE: 258 - FINAL SCORE: 9 - Temperature: 0.10984950047216527\n",
      "EPISODE: 259 - FINAL SCORE: 12 - Temperature: 0.10822960054428549\n",
      "EPISODE: 260 - FINAL SCORE: 15 - Temperature: 0.1066335885336476\n",
      "Updating target network...\n",
      "EPISODE: 261 - FINAL SCORE: 11 - Temperature: 0.10506111217615167\n",
      "EPISODE: 262 - FINAL SCORE: 12 - Temperature: 0.10351182440237394\n",
      "EPISODE: 263 - FINAL SCORE: 11 - Temperature: 0.10198538326096339\n",
      "EPISODE: 264 - FINAL SCORE: 11 - Temperature: 0.10048145184316792\n",
      "EPISODE: 265 - FINAL SCORE: 8 - Temperature: 0.09899969820847344\n",
      "EPISODE: 266 - FINAL SCORE: 11 - Temperature: 0.09753979531133954\n",
      "EPISODE: 267 - FINAL SCORE: 13 - Temperature: 0.09610142092901557\n",
      "EPISODE: 268 - FINAL SCORE: 13 - Temperature: 0.0946842575904212\n",
      "EPISODE: 269 - FINAL SCORE: 10 - Temperature: 0.09328799250607574\n",
      "EPISODE: 270 - FINAL SCORE: 11 - Temperature: 0.09191231749906073\n",
      "Updating target network...\n",
      "EPISODE: 271 - FINAL SCORE: 16 - Temperature: 0.0905569289370006\n",
      "EPISODE: 272 - FINAL SCORE: 10 - Temperature: 0.0892215276650464\n",
      "EPISODE: 273 - FINAL SCORE: 10 - Temperature: 0.08790581893984782\n",
      "EPISODE: 274 - FINAL SCORE: 10 - Temperature: 0.0866095123644988\n",
      "EPISODE: 275 - FINAL SCORE: 12 - Temperature: 0.08533232182444254\n",
      "EPISODE: 276 - FINAL SCORE: 15 - Temperature: 0.08407396542432168\n",
      "EPISODE: 277 - FINAL SCORE: 9 - Temperature: 0.08283416542575969\n",
      "EPISODE: 278 - FINAL SCORE: 11 - Temperature: 0.08161264818605982\n",
      "EPISODE: 279 - FINAL SCORE: 13 - Temperature: 0.08040914409780794\n",
      "EPISODE: 280 - FINAL SCORE: 11 - Temperature: 0.0792233875293662\n",
      "Updating target network...\n",
      "EPISODE: 281 - FINAL SCORE: 9 - Temperature: 0.07805511676624396\n",
      "EPISODE: 282 - FINAL SCORE: 8 - Temperature: 0.07690407395333354\n",
      "EPISODE: 283 - FINAL SCORE: 11 - Temperature: 0.07577000503799756\n",
      "EPISODE: 284 - FINAL SCORE: 11 - Temperature: 0.07465265971399582\n",
      "EPISODE: 285 - FINAL SCORE: 11 - Temperature: 0.0735517913662387\n",
      "EPISODE: 286 - FINAL SCORE: 9 - Temperature: 0.07246715701635571\n",
      "EPISODE: 287 - FINAL SCORE: 10 - Temperature: 0.07139851726906625\n",
      "EPISODE: 288 - FINAL SCORE: 10 - Temperature: 0.07034563625934158\n",
      "EPISODE: 289 - FINAL SCORE: 10 - Temperature: 0.06930828160034574\n",
      "EPISODE: 290 - FINAL SCORE: 12 - Temperature: 0.06828622433214433\n",
      "Updating target network...\n",
      "EPISODE: 291 - FINAL SCORE: 10 - Temperature: 0.06727923887116945\n",
      "EPISODE: 292 - FINAL SCORE: 10 - Temperature: 0.06628710296043011\n",
      "EPISODE: 293 - FINAL SCORE: 9 - Temperature: 0.06530959762045663\n",
      "EPISODE: 294 - FINAL SCORE: 9 - Temperature: 0.06434650710096862\n",
      "EPISODE: 295 - FINAL SCORE: 11 - Temperature: 0.06339761883325559\n",
      "EPISODE: 296 - FINAL SCORE: 11 - Temperature: 0.06246272338325977\n",
      "EPISODE: 297 - FINAL SCORE: 9 - Temperature: 0.06154161440535089\n",
      "EPISODE: 298 - FINAL SCORE: 10 - Temperature: 0.06063408859678252\n",
      "EPISODE: 299 - FINAL SCORE: 10 - Temperature: 0.059739945652820085\n",
      "EPISODE: 300 - FINAL SCORE: 12 - Temperature: 0.05885898822253058\n",
      "Updating target network...\n",
      "EPISODE: 301 - FINAL SCORE: 9 - Temperature: 0.05799102186522416\n",
      "EPISODE: 302 - FINAL SCORE: 11 - Temperature: 0.05713585500753822\n",
      "EPISODE: 303 - FINAL SCORE: 10 - Temperature: 0.05629329890115417\n",
      "EPISODE: 304 - FINAL SCORE: 10 - Temperature: 0.055463167581137826\n",
      "EPISODE: 305 - FINAL SCORE: 10 - Temperature: 0.05464527782489414\n",
      "EPISODE: 306 - FINAL SCORE: 9 - Temperature: 0.053839449111727194\n",
      "EPISODE: 307 - FINAL SCORE: 10 - Temperature: 0.05304550358299651\n",
      "EPISODE: 308 - FINAL SCORE: 10 - Temperature: 0.05226326600286099\n",
      "EPISODE: 309 - FINAL SCORE: 10 - Temperature: 0.05149256371960165\n",
      "EPISODE: 310 - FINAL SCORE: 8 - Temperature: 0.05073322662751478\n",
      "Updating target network...\n",
      "EPISODE: 311 - FINAL SCORE: 9 - Temperature: 0.04998508712936709\n",
      "EPISODE: 312 - FINAL SCORE: 10 - Temperature: 0.04924798009940438\n",
      "EPISODE: 313 - FINAL SCORE: 9 - Temperature: 0.04852174284690577\n",
      "EPISODE: 314 - FINAL SCORE: 10 - Temperature: 0.04780621508027545\n",
      "EPISODE: 315 - FINAL SCORE: 11 - Temperature: 0.04710123887166386\n",
      "EPISODE: 316 - FINAL SCORE: 10 - Temperature: 0.04640665862211061\n",
      "EPISODE: 317 - FINAL SCORE: 11 - Temperature: 0.04572232102720141\n",
      "EPISODE: 318 - FINAL SCORE: 11 - Temperature: 0.04504807504323148\n",
      "EPISODE: 319 - FINAL SCORE: 9 - Temperature: 0.04438377185386792\n",
      "EPISODE: 320 - FINAL SCORE: 11 - Temperature: 0.04372926483730364\n",
      "Updating target network...\n",
      "EPISODE: 321 - FINAL SCORE: 10 - Temperature: 0.04308440953389574\n",
      "EPISODE: 322 - FINAL SCORE: 10 - Temperature: 0.04244906361428106\n",
      "EPISODE: 323 - FINAL SCORE: 9 - Temperature: 0.04182308684796193\n",
      "EPISODE: 324 - FINAL SCORE: 10 - Temperature: 0.04120634107235514\n",
      "EPISODE: 325 - FINAL SCORE: 9 - Temperature: 0.04059869016229741\n",
      "EPISODE: 326 - FINAL SCORE: 8 - Temperature: 0.040000000000000466\n",
      "EPISODE: 327 - FINAL SCORE: 9 - Temperature: 0.039410138445449196\n",
      "EPISODE: 328 - FINAL SCORE: 9 - Temperature: 0.03882897530723636\n",
      "EPISODE: 329 - FINAL SCORE: 11 - Temperature: 0.038256382313827386\n",
      "EPISODE: 330 - FINAL SCORE: 10 - Temperature: 0.03769223308524884\n",
      "Updating target network...\n",
      "EPISODE: 331 - FINAL SCORE: 12 - Temperature: 0.037136403105194504\n",
      "EPISODE: 332 - FINAL SCORE: 10 - Temperature: 0.036588769693542696\n",
      "EPISODE: 333 - FINAL SCORE: 9 - Temperature: 0.03604921197927891\n",
      "EPISODE: 334 - FINAL SCORE: 10 - Temperature: 0.03551761087381777\n",
      "EPISODE: 335 - FINAL SCORE: 10 - Temperature: 0.03499384904471835\n",
      "EPISODE: 336 - FINAL SCORE: 9 - Temperature: 0.034477810889787096\n",
      "EPISODE: 337 - FINAL SCORE: 9 - Temperature: 0.033969382511562736\n",
      "EPISODE: 338 - FINAL SCORE: 9 - Temperature: 0.03346845169217732\n",
      "EPISODE: 339 - FINAL SCORE: 9 - Temperature: 0.03297490786858802\n",
      "EPISODE: 340 - FINAL SCORE: 11 - Temperature: 0.03248864210817427\n",
      "Updating target network...\n",
      "EPISODE: 341 - FINAL SCORE: 10 - Temperature: 0.032009547084694584\n",
      "EPISODE: 342 - FINAL SCORE: 10 - Temperature: 0.03153751705459809\n",
      "EPISODE: 343 - FINAL SCORE: 9 - Temperature: 0.031072447833685284\n",
      "EPISODE: 344 - FINAL SCORE: 10 - Temperature: 0.030614236774113016\n",
      "EPISODE: 345 - FINAL SCORE: 8 - Temperature: 0.030162782741738545\n",
      "EPISODE: 346 - FINAL SCORE: 9 - Temperature: 0.029717986093797697\n",
      "EPISODE: 347 - FINAL SCORE: 8 - Temperature: 0.029279748656912186\n",
      "EPISODE: 348 - FINAL SCORE: 9 - Temperature: 0.02884797370542127\n",
      "EPISODE: 349 - FINAL SCORE: 9 - Temperature: 0.028422565940032927\n",
      "EPISODE: 350 - FINAL SCORE: 11 - Temperature: 0.028003431466789835\n",
      "Updating target network...\n",
      "EPISODE: 351 - FINAL SCORE: 9 - Temperature: 0.027590477776345577\n",
      "EPISODE: 352 - FINAL SCORE: 9 - Temperature: 0.027183613723546392\n",
      "EPISODE: 353 - FINAL SCORE: 9 - Temperature: 0.026782749507314085\n",
      "EPISODE: 354 - FINAL SCORE: 9 - Temperature: 0.02638779665082555\n",
      "EPISODE: 355 - FINAL SCORE: 10 - Temperature: 0.025998667981984584\n",
      "EPISODE: 356 - FINAL SCORE: 8 - Temperature: 0.025615277614181694\n",
      "EPISODE: 357 - FINAL SCORE: 9 - Temperature: 0.02523754092733761\n",
      "EPISODE: 358 - FINAL SCORE: 8 - Temperature: 0.024865374549226344\n",
      "EPISODE: 359 - FINAL SCORE: 10 - Temperature: 0.02449869633707369\n",
      "EPISODE: 360 - FINAL SCORE: 8 - Temperature: 0.02413742535942705\n",
      "Updating target network...\n",
      "EPISODE: 361 - FINAL SCORE: 9 - Temperature: 0.02378148187829263\n",
      "EPISODE: 362 - FINAL SCORE: 10 - Temperature: 0.02343078733153607\n",
      "EPISODE: 363 - FINAL SCORE: 8 - Temperature: 0.023085264315542572\n",
      "EPISODE: 364 - FINAL SCORE: 9 - Temperature: 0.02274483656813275\n",
      "EPISODE: 365 - FINAL SCORE: 10 - Temperature: 0.02240942895173042\n",
      "EPISODE: 366 - FINAL SCORE: 10 - Temperature: 0.02207896743677857\n",
      "EPISODE: 367 - FINAL SCORE: 9 - Temperature: 0.021753379085399947\n",
      "EPISODE: 368 - FINAL SCORE: 9 - Temperature: 0.021432592035298525\n",
      "EPISODE: 369 - FINAL SCORE: 9 - Temperature: 0.021116535483898417\n",
      "EPISODE: 370 - FINAL SCORE: 9 - Temperature: 0.020805139672716685\n",
      "Updating target network...\n",
      "EPISODE: 371 - FINAL SCORE: 9 - Temperature: 0.020498335871966564\n",
      "EPISODE: 372 - FINAL SCORE: 10 - Temperature: 0.02019605636538776\n",
      "EPISODE: 373 - FINAL SCORE: 9 - Temperature: 0.019898234435300446\n",
      "EPISODE: 374 - FINAL SCORE: 9 - Temperature: 0.01960480434787965\n",
      "EPISODE: 375 - FINAL SCORE: 9 - Temperature: 0.019315701338646806\n",
      "EPISODE: 376 - FINAL SCORE: 10 - Temperature: 0.019030861598175252\n",
      "EPISODE: 377 - FINAL SCORE: 9 - Temperature: 0.018750222258006512\n",
      "EPISODE: 378 - FINAL SCORE: 9 - Temperature: 0.018473721376774277\n",
      "EPISODE: 379 - FINAL SCORE: 9 - Temperature: 0.018201297926533\n",
      "EPISODE: 380 - FINAL SCORE: 10 - Temperature: 0.017932891779288113\n",
      "Updating target network...\n",
      "EPISODE: 381 - FINAL SCORE: 10 - Temperature: 0.01766844369372485\n",
      "EPISODE: 382 - FINAL SCORE: 10 - Temperature: 0.017407895302132798\n",
      "EPISODE: 383 - FINAL SCORE: 9 - Temperature: 0.017151189097523258\n",
      "EPISODE: 384 - FINAL SCORE: 9 - Temperature: 0.016898268420936564\n",
      "EPISODE: 385 - FINAL SCORE: 8 - Temperature: 0.016649077448936605\n",
      "EPISODE: 386 - FINAL SCORE: 9 - Temperature: 0.01640356118128975\n",
      "EPISODE: 387 - FINAL SCORE: 9 - Temperature: 0.016161665428825443\n",
      "EPISODE: 388 - FINAL SCORE: 9 - Temperature: 0.015923336801475833\n",
      "EPISODE: 389 - FINAL SCORE: 10 - Temperature: 0.015688522696491784\n",
      "EPISODE: 390 - FINAL SCORE: 10 - Temperature: 0.015457171286832648\n",
      "Updating target network...\n",
      "EPISODE: 391 - FINAL SCORE: 9 - Temperature: 0.015229231509727242\n",
      "EPISODE: 392 - FINAL SCORE: 10 - Temperature: 0.015004653055403522\n",
      "EPISODE: 393 - FINAL SCORE: 10 - Temperature: 0.014783386355984455\n",
      "EPISODE: 394 - FINAL SCORE: 9 - Temperature: 0.014565382574547628\n",
      "EPISODE: 395 - FINAL SCORE: 8 - Temperature: 0.014350593594346215\n",
      "EPISODE: 396 - FINAL SCORE: 10 - Temperature: 0.014138972008188852\n",
      "EPISODE: 397 - FINAL SCORE: 10 - Temperature: 0.013930471107976175\n",
      "EPISODE: 398 - FINAL SCORE: 9 - Temperature: 0.013725044874391619\n",
      "EPISODE: 399 - FINAL SCORE: 9 - Temperature: 0.013522647966744253\n",
      "EPISODE: 400 - FINAL SCORE: 10 - Temperature: 0.013323235712961424\n",
      "Updating target network...\n",
      "EPISODE: 401 - FINAL SCORE: 10 - Temperature: 0.013126764099728913\n",
      "EPISODE: 402 - FINAL SCORE: 9 - Temperature: 0.012933189762776567\n",
      "EPISODE: 403 - FINAL SCORE: 9 - Temperature: 0.01274246997730712\n",
      "EPISODE: 404 - FINAL SCORE: 9 - Temperature: 0.012554562648566192\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13074/4085857486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Visually render the environment (disable to speed up the training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Set the current state for the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rgb_array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mglClearColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mThe\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mactive\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \"\"\"\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglClear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGL_COLOR_BUFFER_BIT\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGL_DEPTH_BUFFER_BIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyglet/gl/lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_debug_gl_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the Gym environment\n",
    "env = gym.make('CartPole-v1') \n",
    "env.seed(0) # Set a random seed for the environment (reproducible results)\n",
    "\n",
    "for episode_num, tau in enumerate(tqdm(exploration_profile)):\n",
    "\n",
    "    # Reset the environment and get the initial state\n",
    "    state = env.reset()\n",
    "    # Reset the score. The final score will be the total amount of steps before the pole falls\n",
    "    score = 0\n",
    "    done = False\n",
    "\n",
    "    # Go on until the pole falls off\n",
    "    while not done:\n",
    "\n",
    "        # Choose the action following the policy\n",
    "        action, q_values = choose_action_softmax(policy_net, state, temperature=tau)\n",
    "      \n",
    "        # Apply the action and get the next state, the reward and a flag \"done\" that is True if the game is ended\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # We apply a (linear) penalty when the cart is far from center\n",
    "        pos_weight = 1\n",
    "        reward = reward - pos_weight * np.abs(state[0]) \n",
    "\n",
    "        # Update the final score (+1 for each step)\n",
    "        score += 1\n",
    "\n",
    "        # Apply penalty for bad state\n",
    "        if done: # if the pole has fallen down \n",
    "            reward += bad_state_penalty\n",
    "            next_state = None\n",
    "\n",
    "        # Update the replay memory\n",
    "        replay_mem.push(state, action, next_state, reward)\n",
    "\n",
    "        # Update the network\n",
    "        if len(replay_mem) > min_samples_for_training: # we enable the training only if we have enough samples in the replay memory, otherwise the training will use the same samples too often\n",
    "            update_step(policy_net, target_net, replay_mem, gamma, optimizer, loss_fn, batch_size)\n",
    "\n",
    "        # Visually render the environment (disable to speed up the training)\n",
    "        env.render()\n",
    "\n",
    "        # Set the current state for the next iteration\n",
    "        state = next_state\n",
    "\n",
    "    # Update the target network every target_net_update_steps episodes\n",
    "    if episode_num % target_net_update_steps == 0:\n",
    "        print('Updating target network...')\n",
    "        target_net.load_state_dict(policy_net.state_dict()) # This will copy the weights of the policy network to the target network\n",
    "\n",
    "    # Print the final score\n",
    "    print(f\"EPISODE: {episode_num + 1} - FINAL SCORE: {score} - Temperature: {tau}\") # Print the final score\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3ac15-e1d7-4a3a-a993-30465fab50a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Resources:\n",
    "* [Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
